[["index.html", "統計推論再考 – 理論と実践 – 目指すもの", " 統計推論再考 – 理論と実践 – By Chishio Furukawa 目指すもの データ保存・計算の飛躍的な技術革新を背景とし、データ分析を体系的に理解・実践する知識・技能の社会的意義が高まっている。本講義「ミクロ・データサイエンス」は、以下の二つのことを目的としている。 社会経済の理解の基盤となるデータ分析について、批判的に吟味できること (すなわち、結論を無批判・無反省に受け入れるのではなく、その仮定に気づき吟味できること) 日進月歩のプログラミング環境の中でも、その根本にある基礎概念は普遍的である。実際に経験することでそれらを学び、プログラミングをこれから独立して学び続けていくための知識・技能を体得すること 講義内容全体のマインドマップ: どう学ぶか 講義ビデオを確認できるため、ノートを自分で取ることの意義を見出しづらいかもしれない。しかし、本講義で用いている数式を理解するため、こつこつ自分の手でノートを取って考えて行こう。 講義ビデオが長くなってしまうときについては、目次において、特に重要なビデオに*をつけて強調している 講義では、自分でも気づかず「言い間違い」をしてしまうことがある。「あれ？」と思ったら、連絡をしてほしい "],["主要な8の統計的考え方.html", "1 主要な8の統計的考え方", " 1 主要な8の統計的考え方 統計的手法は、多数の層から成る論理が積み重なっている山のようである。基礎から一歩一歩理解を進めていくためにも、まず、何を目指しているのか、その主要な考え方を見渡そう。 統計的思考への社会の要請 主要な考え方(1)確率分布 主要な考え方(2)最適化 主要な考え方(3)人間的制約 0. 統計的思考への社会の要請 要点 『データ・サイエンス』とは、数理統計学、コンピュータ・サイエンス、対象の専門知識から成る学際的な手法群である よくある誤解 ビッグ・データがあれば、何でも分かる 統計学は専門家が理解していれば十分である 1. 主要な考え方(1)確率分布 要点 統計学 = 体系的に観察から理解を導出する概念装置 多くの自然・社会現象は、確率分布に従う 標本(現象の観察)と仮定を組み合わせて、確率分布を推測する 意思決定に役立つ情報とは、確率分布について分別できるものだ 2. 主要な考え方(2)最適化 要点 誤差の総和を、偶発誤差と系統誤差に分解できる 標本を大量に観察することで、偶発誤差を回避できる 標本を無作為に観察することで、系統誤差を回避できる 3. 主要な考え方(3)人間的制約 要点 強い仮定を置けば、脆弱だけれど明確な理解が得られる 複雑な仮定を置けば、解釈できないが精緻な理解が得られる "],["プログラミングの姿勢と技術.html", "2 プログラミングの姿勢と技術", " 2 プログラミングの姿勢と技術 実証研究とは、つまるところ、データを「インプット」とし、解析結果を「アウトプット」とするプログラムを書くことである。再現可能なプログラムを書くための心得を習慣づけよう。 プログラムの再現可能性* Rの特徴と初期設定 変数と関数の概念* Rプログラムの事始 RMarkdownの事始 便利なcheat sheet 1. プログラムの再現可能性 要点 再現可能性を向上し、信頼性と拡張可能性を改善するために、データ分析のためにスクリプトを用いてプログラミングをする データ分析プロジェクトの規模が大きくなると、たとえ時間をかけても、小さなミスを絶対に避けるための努力が要求される 2. Rの特徴と初期設定 要点 Rの強みは、オープン・ソースだからユーザーベースが広く、再現可能性に優れている点である Rの弱みは、計算効率があまり高くないことである まず初期設定をしよう 3. 変数と関数の概念 要点 変数とは、「名札」のついた情報を格納できる「箱」である。関数とは、「名札」のついた、引数に特定の操作をする「筒」である。 自己文書化を目指そう。コメントをせずとも、関数や変数の「名札」を使って、分析内容が分かるようにすることができる。 「名札」は、他人が読んで分からないほど省略しすぎない 「名札」のつけ方には、アルファベットと数字、そして「_」や「.」を使う 訂正: 「オブジェクト」は「変数」より広い概念で、「関数」を含めることもある 4. Rプログラムの事始 要点 頻繁に使うコマンドのためには、Cheat Sheetを印刷して、手引きとしてすぐに使えるようにしよう エラー・メッセージなど、インターネットで検索すると、他の人が同じエラーを経験し、掲示板で質疑応答があることが多い 追加点: 英語話者のユーザーベースが広いため、Sys.setenv(LANG = \"en\")でエラーメッセージを英語で表示するように設定し、検索して解決策を見つけやすくしよう 5. RMarkdownの事始 要点 Rmarkdownを使って、コマンド、文書とアウトプットを組み合わせ、再現可能なプログラミングに近づける htmlもしくはMS Wordで出力し、PDFに変換して宿題を提出すること 便利なcheat sheet Cheat Sheetを印刷して、手引きとして適切なコマンドをすぐに見つけられるようにしよう Base R RMarkdown "],["確率変数と確率分布.html", "3 確率変数と確率分布", " 3 確率変数と確率分布 確率分布は、すべての統計的推論の基盤となる「概念装置」である。この「装置」は極めて抽象的であり、最初は、具体的にどう役立つか見えづらいかもしれない。講義全体で最も分かりづらいと覚悟して、ここではまずその「装置」に触れてほしい。 確率変数と確率分布 確率変数のばらつき 連続型と離散型の確率分布 モンテ・カルロ法と逆関数法 プログラミングに便利なコツ 1. 確率変数と確率分布 要点 確率変数とは、事象空間から実数空間への「関数」である \\(F(x)\\) が分布関数となる条件とは、分位関数( \\(F^{-1}(q)\\approx\\)分布関数の「逆関数」)が存在することである 確率変数の中心的傾向を表す代表値である期待値\\(\\mu\\)と中央値\\(m\\)を、分位関数を用いて定義できる \\[ \\mu = \\mathbb{E}[X] \\equiv \\int ^1_0 F^{-1}(q)dq \\\\ m \\equiv F^{-1}(\\frac{1}{2}) \\] 確率変数\\(Y = aX + b\\) の期待値について、以下の関係が成り立つ \\[ \\mathbb{E}[Y] = a\\mu + b \\] 2. 確率変数のばらつき 要点 確率変数のばらつきを表現するために、分散\\(V\\)や絶対偏差\\(AD\\) を用いる \\[ \\sigma^2 = V(X) \\equiv \\mathbb{E} [(X - \\mu)^2]\\\\ AD(X) \\equiv \\mathbb{E} |X - \\mu| \\] 平均二乗誤差(MSE = Mean Squared Error)は、系統誤差Bias \\(= \\mathbb{E}[\\hat{\\mu} - \\mu]\\) の二乗と偶発誤差Variance \\(= V(\\hat{\\mu})\\) に分解できる \\[ MSE \\equiv V(\\hat{\\mu} - \\mu ) = \\mathbb{E}[\\hat{\\mu} - \\mu]^2 + V(\\hat{\\mu}) \\] 確率変数\\(Y = aX + b\\) の分散について、以下の関係が成り立つ \\[ V (Y) = a^2 \\sigma^2 \\] 3. 連続型と離散型の確率分布 要点 分布関数の増加の度合を表現するために、連続型については微分可能なときに確率密度関数(probability density function)を用い、離散型については確率質量関数(probability mass function)を用いる 計測するとき・コンピュータにおいては、実際に連続的であっても離散的に扱う。 概念的に議論するときにおいては、厳密には離散的であっても連続的に考える 「連続型かつ離散型である」分布や、「連続型でも離散型でもない」分布も存在する 4. モンテ・カルロ法と逆関数法 要点 コンピュータでは、確定的である「疑似乱数」を用いて確率変数をシミュレーションする 逆関数法を用いて、(分位関数を近似できる一次元の)あらゆる分布のシミュレーションを行うことができる プログラミングに便利なコツ function()をコマンドのブロックのタイトルとして活用することによって、可読性に優れ、また分割可能なコードを書くことができる function()がコマンドの意味を示しているの、コメントを書く必要がほとんどない！これが、「自己文書化」である 頻繁に使う操作について、ショートカットキーを活用しよう RStudio以外にも共通するもの Ctrl + Z -&gt; 戻る Ctrl + X -&gt; 切り取り Ctrl + C -&gt; コピー Ctrl + V -&gt; 貼り付け Ctrl + F -&gt; 探す Windows + 右・左 -&gt; 画面の分割 コマンドとしてはギリシャ文字をアルファベットで使用する(e.g. \\(\\varepsilon \\rightarrow\\) epsilon) RStudioにおける便利なコマンド Ctrl + Enter -&gt; ハイライトしたセクション・もしくはカーソルのある行の実行 Ctrl + Shift + Enter -&gt; Rスクリプトの全体の実行 Ctrl + Shift + C -&gt; ハイライトしたセクションをコメント・アウトもしくはコメント・アウトのキャンセル "],["典型的分布と大標本定理.html", "4 典型的分布と大標本定理", " 4 典型的分布と大標本定理 複雑な自然・社会現象であっても、いくつかの典型的な確率分布でモデルできる。ここでは、経済学分析においてもっとも重要な確率分布について、形成過程やその性質を具体的に考えていく。この確率論が、大数の法則や中心極限定理など、今後の統計推論のために欠かせない大標本定理につながっていく。 典型的確率分布について* 指数分布…待機問題の分布 正規分布…組み合わせ問題の分布 標本平均の大標本定理 … 大数の法則と中心極限定理* べき分布 … 分散が無限大となりうる分布 この講義では、正規分布を導出する確率過程や「べき分布」など、発展的なテーマも考えていく。これらの数式の詳細を、深く理解しなくても大丈夫。なぜ結論が成り立っているか、アプローチを把握してもらいたい。 1. 典型的確率分布について 要点: 確率過程によって形成される分布によって、多くの社会・自然現象を理解できる 「並列的な」和もしくは「直列的な」積の過程によって形成される 社会現象は積の過程によって形成されることが多い 2. 指数分布…待機問題の分布 要点: 独立した事象の待ち時間は指数分布に従い、\\(f(t) \\propto \\exp\\{-\\lambda t\\}\\) で定義される 指数分布では、密度の減少率が一定である \\[ \\frac{\\partial \\ln f(t)}{\\partial t} = - \\lambda . \\] 3. 正規分布…組み合わせ問題の分布 要点: 独立した確率変数の総和は正規分布で近似され、\\(f(t) \\propto \\exp\\{- t^2/2\\}\\) で定義される 正規分布では、対数密度が放物線となる。すなわち、密度の減少率が、中心からの距離に比例して増加する \\[ \\frac{\\partial \\ln f(t)}{\\partial t} = - t . \\] よって、中心から離れた値を取る確率が極めて低い 正規分布は、パスカルの三角形を用いて、組み合わせの「場合の数」から導出できる 4. 標本平均の大標本定理 … 大数の法則と中心極限定理 要点: ある分布から独立した\\(n\\)個の観察\\(X_{t}\\)の標本平均を以下のように定義する \\[ \\overline{X}_{n} \\equiv \\sum^{n}_{t=1} X_{t}/n \\] 大数の法則: 標本数が増えるにしたがって、標本平均が、分布の期待値に収束する \\[ \\text{As} \\:\\: n \\rightarrow \\infty, \\overline{X}_{n} \\rightarrow \\mu \\] (古典的)中心極限定理: 分布の分散が有限 \\(\\sigma^2 &lt; \\infty\\) のとき、標本数が増えるにしたがって、標本平均の分布が正規分布に従う \\[ \\text{As} \\:\\: n \\rightarrow \\infty, \\overline{X}_{n} \\rightarrow \\cal{N} \\:(\\mu,\\frac{\\sigma^2}{n}) \\] 5. べき分布 … 分散が無限大となりうる分布 要点: べき分布は、中心から離れた値を取る確率が極めて高くなることがある。このようなとき、分布の分散が無限大となり(もしくは非常に大きくなり)、標本平均が、分布の期待値に収束するために膨大な標本数が必要となることがある 例: 地震のエネルギー、富の分布、企業規模など "],["条件づき確率と意思決定.html", "5 条件づき確率と意思決定", " 5 条件づき確率と意思決定 ここまで、確率分布の定義やその形成過程について考えてきました。ここでは、個々人の「考え」や「知識」を確率分布として表す枠組みを説明します。これから、データの比較分析に基づく統計手法について学んでいきます。しかし、日常生活は貧弱なデータしかなく、不確実性の残る下で意思決定を迫られることばかりです。ミクロ経済学の期待効用理論に基づいて、統計分析と日常的観察による知識を結び付けて考える方法を、まずここで考えたいと思います。 条件づき確率とベイズの定理* 正規分布とベイズの定理 期待効用理論と情報の価値* この講義は、統計手法の「実践」よりも、その解釈のための「教養」を重視した内容となっています。すぐには役に立たなくても、今後いつか、自分の考えを整理する一助となると思い、学んでください。 1. 条件づき確率とベイズの定理 要点 条件づき確率\\(\\mathbb{P}(A|B)\\)は、以下のように定義される \\[ \\mathbb{P}(A|B) = \\frac{\\mathbb{P}(AB)}{\\mathbb{P}(B)} \\] ベイズの定理: 条件づき確率には「内部対称性」があり、定義から以下のように書き換えることができる \\[ \\mathbb{P}(A|B) = \\frac{\\mathbb{P}(A)\\mathbb{P}(B|A)}{\\mathbb{P}(B)} \\] よって、「原因に条件づけて、結果の確率を推察できる」ことと同じように、「観察された結果に条件づけて、原因の確率を推察できる」(!) 2. 正規分布とベイズの定理 要点 ベイズの定理は、事後分布(posterior distribution)は、事前確率(prior distribution)と信号(signal)を組み合わせたものだと捉えることができる 正規分布の事前分布 \\(\\theta\\sim{\\cal N}\\left(\\theta_{0},1/\\psi_{0}\\right)\\) と信号 \\(s\\sim{\\cal N}\\left(\\theta,1/\\psi_{\\varepsilon}\\right)\\) を組み合わせるとき、事後分布は正規分布\\(\\theta\\sim{\\cal N}\\left(\\theta_{1},1/\\psi_{1}\\right)\\)に従う。ただし、 \\[ \\begin{align*} \\theta_{1} &amp; =\\frac{\\psi_{0}}{\\psi_{0}+\\psi_{s}}\\theta_{0}+\\frac{\\psi_{s}}{\\psi_{0}+\\psi_{s}} s\\\\ \\psi_{1} &amp; =\\psi_{0}+\\psi_{s} \\end{align*} \\] 訂正: \\(\\ln \\mathbb{P}(\\theta|s) = \\ln \\mathbb{P}(\\theta) + \\ln \\mathbb{P}(s|\\theta) - \\ln \\mathbb{P}(s)\\) が正しいベイズの定理であり、 \\(\\ln \\mathbb{P}(s)\\)の項の前は負の符号です。 3. 期待効用理論と情報の価値 要点 情報の欠如を、期待効用最大化問題の「予算制約」のように捉えることができる ブラックウェルの定理: より役に立つ情報とは、この制約を緩和するものである 情報の中には、どちらがより役に立つか立たないか順序づけることはできないものもある(例えば、インターネットの上で画像データが蓄積されることにより保存されている「情報量」は増えるかもしれないが、社会的に重要な意思決定をより正しくする重要な情報が増えているとは限らない) より役に立つ情報とは、意思決定に重要な状態に関して、異なる状況をより正確に「分別」できるようにするものである "],["推定方法1最尤法.html", "6 推定方法(1)最尤法", " 6 推定方法(1)最尤法 「確率」という概念に基づき、個人の知識を確率分布として捉える考え方を学びました。事前分布は置いておいて、標本分布から母集団分布についてどう学べるかという推定法について、これから学んでいきます。多くある推定法の中でも一般的である「最尤法」と、その根拠となる「尤度」の概念について考えます。その後、具体的に最尤推定量を得るための「数値的アプローチ」について紹介します。 推定の概要* 最尤法* 解析的・数値的アプローチについて 最適化アルゴリズム 1. 推定の概要 要点 現実に観察されるデータを「標本」とし、「仮説的無限母集団」や「潜在的結果」を想定し、その母集団分布について推測をする 推測の目的には、複数の異なるものがある パラメトリック法: データの縮約 … いくつかの母数(パラメータ)によって母集団分布をモデルし、その母数を推定する ノン・パラメトリック法: 結果の近似 … 特定のモデルを想定せず、母集団分布の近似・予測を目的として、多次元のモデルを推定する 2. 最尤法 要点 特定の標本\\(x\\)を所与として、あるパラメータ\\(\\theta\\)を想定する「もっともらしさ」の指標を尤度(likelihood)と呼び、その関数である尤度関数\\(\\cal{L}(\\theta|x)\\) は、 \\[ \\cal{L}(\\theta|x) = k f(x|\\theta) \\] を満たす. ここで、\\(f(x|\\theta)\\)は分布の密度関数もしくは質量関数であり、\\(k&gt;0\\)は任意の定数である. 尤度原則(likelihood principle) … データから推測できる全ての情報は、尤度\\(\\cal{L}(\\theta|x)\\) にまとめられている 最尤原理(maximum likelihood principle) … 標本は『尤度』が最大のものが実現したと仮定する 対数尤度を最大化し、最尤法を解く \\[ \\max_\\theta \\ln \\cal{L}(\\theta|x) = \\sum_{i=1}^{n} \\ln f(x_i|\\theta) + \\ln k \\] ベイズの定理における事前分布の情報を(ある特定の意味で)消去したものが最尤法だと解釈できる. 推定の段階で事前分布は使われていないが、解釈するときに、先験知=事前分布を組み合わせることができる. 3. 解析的・数値的アプローチについて 要点 最適化問題の解法には、解析的アプローチと数値的アプローチがあり、 解析的アプローチは厳密であり証明を用いて命題を示すが、数値的アプローチは近似的でありアルゴリズムを用いてシミュレーションの事例を示す 解析的アプローチで扱える分布などは限定的だが、数値的アプローチは汎用的でありほぼどのような問題でも解ける 4. 最適化アルゴリズム 要点 最適化問題を解くために、様々なアルゴリズムから効率がよく精度が高いものを選びたい 最適化アルゴリズムでは、初期値や許容誤差などを設定しなければいけない場合があり、これらが適切に設定されなければ、最適解に到達しないことがある 局所解に収束し、全体解に到達しない場合 最適化問題がとても平らであるため、許容誤差が十分に狭くない場合 変数の次元が増えると探索しなければいけない次元が指数関数的に増える "],["回帰分析と最小二乗法.html", "7 回帰分析と最小二乗法", " 7 回帰分析と最小二乗法 「ベイズの定理」と「最尤法」を用いて、観察から母数についてどう学べるか、という推定の問題を考えてきました。ここでは、2つの確率変数の関係性を分析するための回帰分析とその最も実用的な推定方法である最小二乗法について、2回を通じて学んでいきます。まず、ここでは二つの確率変数の関係について考察し、最小二乗法の概要を説明します。 相関関係と回帰分析の概要 2つの確率変数の確率分布 最小二乗法 なぜ最小二乗法を使うのか 1. 相関関係と回帰分析の概要 要点 多くの事象は、お互いにペアとなって変動する。これらの事象を反映する2つの確率変数\\(X\\)と\\(Y\\)の間に「相関関係がある」と言う 2つの確率変数の観察に相関が見られる理由は、4つある 偶然 \\(X\\)から\\(Y\\)への因果 \\(Y\\)から\\(X\\)への逆因果 交絡因子\\(Z\\)から\\(X\\)と\\(Y\\)への因果 よって、相関は必ずしも因果を示唆しない。しかし、多くの場合、相関は因果を反映している。 \\(X\\)によって\\(Y\\)を説明する関係式を推定することを「回帰分析」と呼ぶ。このとき、\\(X\\)を説明変数もしくは独立変数と呼び、\\(Y\\)を被説明変数もしくは従属変数と呼ぶ 計測した\\(X\\)と\\(Y\\)の関係式に\\(X\\)を代入し、\\(Y\\)の理論値を計算することを「予測」と言う 2. 2つの確率変数の確率分布 要点 あらゆる2つの確率変数の和について、以下の関係が成り立つ $$ = _X + _Y\\ V (X + Y ) = ^2_X + ^2_Y + 2 Cov(X,Y) $$ ここで、$Cov(X,Y) = $を共分散と呼ぶ。 確率変数の値から期待値を差し引き、標準偏差で割ることを、標準化と呼ぶ (すなわち、 \\(X^{\\ast}\\equiv\\frac{X-\\mu_{X}}{\\sigma_{X}}\\), \\(Y^{\\ast}\\equiv\\frac{Y-\\mu_{Y}}{\\sigma_{Y}}\\))。標準化された確率変数の共分散を、相関係数と呼ぶ \\[ \\rho \\equiv \\mathbb{E}\\left[X^\\ast Y^\\ast\\right] \\] また、\\(-1 \\leq \\rho \\leq 1\\) を満たし、相関の強さを表す 2つの確率変数について、独立\\(\\Rightarrow\\)無相関であるが、無相関\\(\\Rightarrow\\)独立ではない 2つの確率変数の分布を同時確率分布と呼び、うち1つの確率変数の特定の値に条件づけた分布を条件つき確率分布と呼ぶ。これらのうち、特に重要なものが二次元正規分布であり、その分散を「分散共分散行列」を用いて表す。(正規分布は分布の形状が特定されているので、二次元正規分布について独立と無相関は同値である。) 3. 最小二乗法 要点 単回帰モデル \\[ Y=\\underset{定数項・切片}{\\underbrace{\\beta_{0}}}+\\underset{傾斜・勾配}{\\underbrace{\\beta_{1}}}X+\\underset{誤差項・錯乱項}{\\underbrace{\\varepsilon}} \\] 単回帰モデルの推定 \\[ Y_{i}=\\underset{=\\hat{Y}_{i}...予測値・理論値}{\\underbrace{\\hat{\\beta}_{0}+\\hat{\\beta}_{1}X_{i}}}+\\underset{残差}{\\hat{\\varepsilon_{i}}} \\] 最小二乗法は、残差の二乗の総和\\(\\sum_i \\hat{\\varepsilon_{i}}^2\\) を最小化することによって、推定量\\(\\hat{\\beta}_{0}, \\hat{\\beta}_{1}\\)を得る 勾配\\(\\beta_1\\)が重要なパラメータとなる場合が多く、 \\[ \\beta_{1}=\\frac{Cov\\left(X,Y\\right)}{Var\\left(X\\right)}=\\rho \\frac{\\sigma_Y}{\\sigma_X} \\] である。 データに対する理論モデルの適合度を決定係数\\(R^2\\)で測り、 \\[ R^{2}=\\frac{\\sum_{i}\\left(\\hat{Y}_{i}-\\overline{Y}\\right)^{2}}{\\sum_{i}\\left(Y_{i}-\\overline{Y}\\right)^{2}}=\\frac{理論モデルで説明されるYの変動}{データにおけるYの変動}= \\hat{\\rho}^2 \\] 4. なぜ最小二乗法を使うのか 要点 どの推定方法が適切かは、推定の目的に応じて変わる。しかし、多くの場合、最小二乗法が適切だと考えられる理由がある。 外れ値などがある場合が例外である。 様々な理由から、最小二乗法が望ましい 予測値を「条件つき期待値」として解釈できる 誤差が正規分布をするときの最尤法である 誤差の2次損失関数の期待値を最小化している 補足説明: 2次のテイラー近似は、近似している値(ここでは真の\\(Y_i\\))の近傍のみにおいて適切である。予測値\\(\\hat{Y}_i\\)が大きく乖離するときは、2次の損失関数と、人間の直観的基準が合致しないことがある。 "],["推定の目的と基準1予測.html", "8 推定の目的と基準(1)予測", " 8 推定の目的と基準(1)予測 "],["推定の目的と基準2仮説検定.html", "9 推定の目的と基準(2)仮説検定", " 9 推定の目的と基準(2)仮説検定 "],["標本抽出.html", "10 標本抽出", " 10 標本抽出 "],["相関と因果実験研究.html", "11 相関と因果…『実験研究』", " 11 相関と因果…『実験研究』 "],["相関と因果観察研究.html", "12 相関と因果…『観察研究』", " 12 相関と因果…『観察研究』 "],["感度分析と縮小推定量.html", "13 感度分析と縮小推定量", " 13 感度分析と縮小推定量 "],["交差検証.html", "14 交差検証", " 14 交差検証 "],["複数の研究の統合.html", "15 複数の研究の統合", " 15 複数の研究の統合 "],["実際のデータ分析における工夫.html", "16 実際のデータ分析における工夫", " 16 実際のデータ分析における工夫 "]]
