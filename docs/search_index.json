[["index.html", "統計推論再考 – 理論と実践 – 目指すもの", " 統計推論再考 – 理論と実践 – By Chishio Furukawa 目指すもの データ保存・計算の飛躍的な技術革新を背景とし、データ分析を体系的に理解・実践する知識・技能の社会的意義が高まっている。本講義「ミクロ・データサイエンス」は、以下の二つのことを目的としている。 社会経済の理解の基盤となるデータ分析について、批判的に吟味できること (すなわち、結論を無批判・無反省に受け入れるのではなく、その仮定に気づき吟味できること) 日進月歩のプログラミング環境の中でも、その根本にある基礎概念は普遍的である。実際に経験することでそれらを学び、プログラミングをこれから独立して学び続けていくための知識・技能を体得すること 講義内容全体のマインドマップ: どう学ぶか 講義ビデオを確認できるため、ノートを自分で取ることの意義を見出しづらいかもしれない。しかし、本講義で用いている数式を理解するため、こつこつ自分の手でノートを取って考えて行こう。 講義ビデオが長くなってしまうときについては、目次において、特に重要なビデオに*をつけて強調している 講義では、自分でも気づかず「言い間違い」をしてしまうことがある。「あれ？」と思ったら、連絡をしてほしい "],["主要な8の統計的考え方.html", "1 主要な8の統計的考え方", " 1 主要な8の統計的考え方 統計的手法は、多数の層から成る論理が積み重なっている山のようである。基礎から一歩一歩理解を進めていくためにも、まず、何を目指しているのか、その主要な考え方を見渡そう。 統計的思考への社会の要請 主要な考え方(1)確率分布 主要な考え方(2)最適化 主要な考え方(3)人間的制約 0. 統計的思考への社会の要請 要点 『データ・サイエンス』とは、数理統計学、コンピュータ・サイエンス、対象の専門知識から成る学際的な手法群である よくある誤解 ビッグ・データがあれば、何でも分かる 統計学は専門家が理解していれば十分である 1. 主要な考え方(1)確率分布 要点 統計学 = 体系的に観察から理解を導出する概念装置 多くの自然・社会現象は、確率分布に従う 標本(現象の観察)と仮定を組み合わせて、確率分布を推測する 意思決定に役立つ情報とは、確率分布について分別できるものだ 2. 主要な考え方(2)最適化 要点 誤差の総和を、偶発誤差と系統誤差に分解できる 標本を大量に観察することで、偶発誤差を回避できる 標本を無作為に観察することで、系統誤差を回避できる 3. 主要な考え方(3)人間的制約 要点 強い仮定を置けば、脆弱だけれど明確な理解が得られる 複雑な仮定を置けば、解釈できないが精緻な理解が得られる "],["プログラミングの姿勢と技術.html", "2 プログラミングの姿勢と技術", " 2 プログラミングの姿勢と技術 実証研究とは、つまるところ、データを「インプット」とし、解析結果を「アウトプット」とするプログラムを書くことである。再現可能なプログラムを書くための心得を習慣づけよう。 プログラムの再現可能性* Rの特徴と初期設定 変数と関数の概念* Rプログラムの事始 RMarkdownの事始 便利なcheat sheet 1. プログラムの再現可能性 要点 再現可能性を向上し、信頼性と拡張可能性を改善するために、データ分析のためにスクリプトを用いてプログラミングをする データ分析プロジェクトの規模が大きくなると、たとえ時間をかけても、小さなミスを絶対に避けるための努力が要求される 2. Rの特徴と初期設定 要点 Rの強みは、オープン・ソースだからユーザーベースが広く、再現可能性に優れている点である Rの弱みは、計算効率があまり高くないことである まず初期設定をしよう 3. 変数と関数の概念 要点 変数とは、「名札」のついた情報を格納できる「箱」である。関数とは、「名札」のついた、引数に特定の操作をする「筒」である。 自己文書化を目指そう。コメントをせずとも、関数や変数の「名札」を使って、分析内容が分かるようにすることができる。 「名札」は、他人が読んで分からないほど省略しすぎない 「名札」のつけ方には、アルファベットと数字、そして「_」や「.」を使う 訂正: 「オブジェクト」は「変数」より広い概念で、「関数」を含めることもある 4. Rプログラムの事始 要点 頻繁に使うコマンドのためには、Cheat Sheetを印刷して、手引きとしてすぐに使えるようにしよう エラー・メッセージなど、インターネットで検索すると、他の人が同じエラーを経験し、掲示板で質疑応答があることが多い 追加点: 英語話者のユーザーベースが広いため、Sys.setenv(LANG = \"en\")でエラーメッセージを英語で表示するように設定し、検索して解決策を見つけやすくしよう 5. RMarkdownの事始 要点 Rmarkdownを使って、コマンド、文書とアウトプットを組み合わせ、再現可能なプログラミングに近づける htmlもしくはMS Wordで出力し、PDFに変換して宿題を提出すること 便利なcheat sheet Cheat Sheetを印刷して、手引きとして適切なコマンドをすぐに見つけられるようにしよう Base R RMarkdown "],["確率変数と確率分布.html", "3 確率変数と確率分布", " 3 確率変数と確率分布 確率分布は、すべての統計的推論の基盤となる「概念装置」である。この「装置」は極めて抽象的であり、最初は、具体的にどう役立つか見えづらいかもしれない。講義全体で最も分かりづらいと覚悟して、ここではまずその「装置」に触れてほしい。 確率変数と確率分布 確率変数のばらつき 連続型と離散型の確率分布 モンテ・カルロ法と逆関数法 プログラミングに便利なコツ 1. 確率変数と確率分布 要点 確率変数とは、事象空間から実数空間への「関数」である \\(F(x)\\) が分布関数となる条件とは、分位関数( \\(F^{-1}(q)\\approx\\)分布関数の「逆関数」)が存在することである 確率変数の中心的傾向を表す代表値である期待値\\(\\mu\\)と中央値\\(m\\)を、分位関数を用いて定義できる \\[ \\mu = \\mathbb{E}[X] \\equiv \\int ^1_0 F^{-1}(q)dq \\\\ m \\equiv F^{-1}(\\frac{1}{2}) \\] 確率変数\\(Y = aX + b\\) の期待値について、以下の関係が成り立つ \\[ \\mathbb{E}[Y] = a\\mu + b \\] 2. 確率変数のばらつき 要点 確率変数のばらつきを表現するために、分散\\(V\\)や絶対偏差\\(AD\\) を用いる \\[ \\sigma^2 = V(X) \\equiv \\mathbb{E} [(X - \\mu)^2]\\\\ AD(X) \\equiv \\mathbb{E} |X - \\mu| \\] 平均二乗誤差(MSE = Mean Squared Error)は、系統誤差Bias \\(= \\mathbb{E}[\\hat{\\mu} - \\mu]\\) の二乗と偶発誤差Variance \\(= V(\\hat{\\mu})\\) に分解できる \\[ MSE \\equiv V(\\hat{\\mu} - \\mu ) = \\mathbb{E}[\\hat{\\mu} - \\mu]^2 + V(\\hat{\\mu}) \\] 確率変数\\(Y = aX + b\\) の分散について、以下の関係が成り立つ \\[ V (Y) = a^2 \\sigma^2 \\] 3. 連続型と離散型の確率分布 要点 分布関数の増加の度合を表現するために、連続型については微分可能なときに確率密度関数(probability density function)を用い、離散型については確率質量関数(probability mass function)を用いる 計測するとき・コンピュータにおいては、実際に連続的であっても離散的に扱う。 概念的に議論するときにおいては、厳密には離散的であっても連続的に考える 「連続型かつ離散型である」分布や、「連続型でも離散型でもない」分布も存在する 4. モンテ・カルロ法と逆関数法 要点 コンピュータでは、確定的である「疑似乱数」を用いて確率変数をシミュレーションする 逆関数法を用いて、(分位関数を近似できる一次元の)あらゆる分布のシミュレーションを行うことができる プログラミングに便利なコツ function()をコマンドのブロックのタイトルとして活用することによって、可読性に優れ、また分割可能なコードを書くことができる function()がコマンドの意味を示しているの、コメントを書く必要がほとんどない！これが、「自己文書化」である 頻繁に使う操作について、ショートカットキーを活用しよう RStudio以外にも共通するもの Ctrl + Z -&gt; 戻る Ctrl + X -&gt; 切り取り Ctrl + C -&gt; コピー Ctrl + V -&gt; 貼り付け Ctrl + F -&gt; 探す Windows + 右・左 -&gt; 画面の分割 コマンドとしてはギリシャ文字をアルファベットで使用する(e.g. \\(\\varepsilon \\rightarrow\\) epsilon) RStudioにおける便利なコマンド Ctrl + Enter -&gt; ハイライトしたセクション・もしくはカーソルのある行の実行 Ctrl + Shift + Enter -&gt; Rスクリプトの全体の実行 Ctrl + Shift + C -&gt; ハイライトしたセクションをコメント・アウトもしくはコメント・アウトのキャンセル "],["典型的分布と大標本定理.html", "4 典型的分布と大標本定理", " 4 典型的分布と大標本定理 複雑な自然・社会現象であっても、いくつかの典型的な確率分布でモデルできる。ここでは、経済学分析においてもっとも重要な確率分布について、形成過程やその性質を具体的に考えていく。この確率論が、大数の法則や中心極限定理など、今後の統計推論のために欠かせない大標本定理につながっていく。 典型的確率分布について* 指数分布…待機問題の分布 正規分布…組み合わせ問題の分布 標本平均の大標本定理 … 大数の法則と中心極限定理* べき分布 … 分散が無限大となりうる分布 この講義では、正規分布を導出する確率過程や「べき分布」など、発展的なテーマも考えていく。これらの数式の詳細を、深く理解しなくても大丈夫。なぜ結論が成り立っているか、アプローチを把握してもらいたい。 1. 典型的確率分布について 要点: 確率過程によって形成される分布によって、多くの社会・自然現象を理解できる 「並列的な」和もしくは「直列的な」積の過程によって形成される 社会現象は積の過程によって形成されることが多い 2. 指数分布…待機問題の分布 要点: 独立した事象の待ち時間は指数分布に従い、\\(f(t) \\propto \\exp\\{-\\lambda t\\}\\) で定義される 指数分布では、密度の減少率が一定である \\[ \\frac{\\partial \\ln f(t)}{\\partial t} = - \\lambda . \\] 3. 正規分布…組み合わせ問題の分布 要点: 独立した確率変数の総和は正規分布で近似され、\\(f(t) \\propto \\exp\\{- t^2/2\\}\\) で定義される 正規分布では、対数密度が放物線となる。すなわち、密度の減少率が、中心からの距離に比例して増加する \\[ \\frac{\\partial \\ln f(t)}{\\partial t} = - t . \\] よって、中心から離れた値を取る確率が極めて低い 正規分布は、パスカルの三角形を用いて、組み合わせの「場合の数」から導出できる 4. 標本平均の大標本定理 … 大数の法則と中心極限定理 要点: ある分布から独立した\\(n\\)個の観察\\(X_{t}\\)の標本平均を以下のように定義する \\[ \\overline{X}_{n} \\equiv \\sum^{n}_{t=1} X_{t}/n \\] 大数の法則: 標本数が増えるにしたがって、標本平均が、分布の期待値に収束する \\[ \\text{As} \\:\\: n \\rightarrow \\infty, \\overline{X}_{n} \\rightarrow \\mu \\] (古典的)中心極限定理: 分布の分散が有限 \\(\\sigma^2 &lt; \\infty\\) のとき、標本数が増えるにしたがって、標本平均の分布が正規分布に従う \\[ \\text{As} \\:\\: n \\rightarrow \\infty, \\overline{X}_{n} \\rightarrow \\cal{N} \\:(\\mu,\\frac{\\sigma^2}{n}) \\] 5. べき分布 … 分散が無限大となりうる分布 要点: べき分布は、中心から離れた値を取る確率が極めて高くなることがある。このようなとき、分布の分散が無限大となり(もしくは非常に大きくなり)、標本平均が、分布の期待値に収束するために膨大な標本数が必要となることがある 例: 地震のエネルギー、富の分布、企業規模など "],["条件づき確率と意思決定.html", "5 条件づき確率と意思決定", " 5 条件づき確率と意思決定 ここまで、確率分布の定義やその形成過程について考えてきました。ここでは、個々人の「考え」や「知識」を確率分布として表す枠組みを説明します。これから、データの比較分析に基づく統計手法について学んでいきます。しかし、日常生活は貧弱なデータしかなく、不確実性の残る下で意思決定を迫られることばかりです。ミクロ経済学の期待効用理論に基づいて、統計分析と日常的観察による知識を結び付けて考える方法を、まずここで考えたいと思います。 条件づき確率とベイズの定理* 正規分布とベイズの定理 期待効用理論と情報の価値* この講義は、統計手法の「実践」よりも、その解釈のための「教養」を重視した内容となっています。すぐには役に立たなくても、今後いつか、自分の考えを整理する一助となると思い、学んでください。 1. 条件づき確率とベイズの定理 要点 条件づき確率\\(\\mathbb{P}(A|B)\\)は、以下のように定義される \\[ \\mathbb{P}(A|B) = \\frac{\\mathbb{P}(AB)}{\\mathbb{P}(B)} \\] ベイズの定理: 条件づき確率には「内部対称性」があり、定義から以下のように書き換えることができる \\[ \\mathbb{P}(A|B) = \\frac{\\mathbb{P}(A)\\mathbb{P}(B|A)}{\\mathbb{P}(B)} \\] よって、「原因に条件づけて、結果の確率を推察できる」ことと同じように、「観察された結果に条件づけて、原因の確率を推察できる」(!) 2. 正規分布とベイズの定理 要点 ベイズの定理は、事後分布(posterior distribution)は、事前確率(prior distribution)と信号(signal)を組み合わせたものだと捉えることができる 正規分布の事前分布 \\(\\theta\\sim{\\cal N}\\left(\\theta_{0},1/\\psi_{0}\\right)\\) と信号 \\(s\\sim{\\cal N}\\left(\\theta,1/\\psi_{\\varepsilon}\\right)\\) を組み合わせるとき、事後分布は正規分布\\(\\theta\\sim{\\cal N}\\left(\\theta_{1},1/\\psi_{1}\\right)\\)に従う。ただし、 \\[ \\begin{align*} \\theta_{1} &amp; =\\frac{\\psi_{0}}{\\psi_{0}+\\psi_{s}}\\theta_{0}+\\frac{\\psi_{s}}{\\psi_{0}+\\psi_{s}} s\\\\ \\psi_{1} &amp; =\\psi_{0}+\\psi_{s} \\end{align*} \\] 訂正: \\(\\ln \\mathbb{P}(\\theta|s) = \\ln \\mathbb{P}(\\theta) + \\ln \\mathbb{P}(s|\\theta) - \\ln \\mathbb{P}(s)\\) が正しいベイズの定理であり、 \\(\\ln \\mathbb{P}(s)\\)の項の前は負の符号です。 3. 期待効用理論と情報の価値 要点 情報の欠如を、期待効用最大化問題の「予算制約」のように捉えることができる ブラックウェルの定理: より役に立つ情報とは、この制約を緩和するものである 情報の中には、どちらがより役に立つか立たないか順序づけることはできないものもある(例えば、インターネットの上で画像データが蓄積されることにより保存されている「情報量」は増えるかもしれないが、社会的に重要な意思決定をより正しくする重要な情報が増えているとは限らない) より役に立つ情報とは、意思決定に重要な状態に関して、異なる状況をより正確に「分別」できるようにするものである "],["最尤法と数値的最適化.html", "6 最尤法と数値的最適化", " 6 最尤法と数値的最適化 「確率」という概念に基づき、個人の知識を確率分布として捉える考え方を学びました。事前分布は置いておいて、標本分布から母集団分布についてどう学べるかという推定法について、これから学んでいきます。多くある推定法の中でも一般的である「最尤法」と、その根拠となる「尤度」の概念について考えます。その後、具体的に最尤推定量を得るための「数値的アプローチ」について紹介します。 推定の概要* 最尤法* 解析的・数値的アプローチについて 最適化アルゴリズム 1. 推定の概要 要点 現実に観察されるデータを「標本」とし、「仮説的無限母集団」や「潜在的結果」を想定し、その母集団分布について推測をする 推測の目的には、複数の異なるものがある パラメトリック法: データの縮約 … いくつかの母数(パラメータ)によって母集団分布をモデルし、その母数を推定する ノン・パラメトリック法: 結果の近似 … 特定のモデルを想定せず、母集団分布の近似・予測を目的として、多次元のモデルを推定する 2. 最尤法 要点 特定の標本\\(x\\)を所与として、あるパラメータ\\(\\theta\\)を想定する「もっともらしさ」の指標を尤度(likelihood)と呼び、その関数である尤度関数\\(\\cal{L}(\\theta|x)\\) は、 \\[ \\cal{L}(\\theta|x) = k f(x|\\theta) \\] を満たす. ここで、\\(f(x|\\theta)\\)は分布の密度関数もしくは質量関数であり、\\(k&gt;0\\)は任意の定数である. 尤度原則(likelihood principle) … データから推測できる全ての情報は、尤度\\(\\cal{L}(\\theta|x)\\) にまとめられている 最尤原理(maximum likelihood principle) … 標本は『尤度』が最大のものが実現したと仮定する 対数尤度を最大化し、最尤法を解く \\[ \\max_\\theta \\ln \\cal{L}(\\theta|x) = \\sum_{i=1}^{n} \\ln f(x_i|\\theta) + \\ln k \\] ベイズの定理における事前分布の情報を(ある特定の意味で)消去したものが最尤法だと解釈できる. 推定の段階で事前分布は使われていないが、解釈するときに、先験知=事前分布を組み合わせることができる. 補足説明: 最小二乗法は、最尤法の一部として捉えることもできるが、ノン・パラメトリック法の近似において使われることも多い。講義ビデオ7.4『なぜ「二乗」なのか』を参考にしてほしい。 3. 解析的・数値的アプローチについて 要点 最適化問題の解法には、解析的アプローチと数値的アプローチがあり、 解析的アプローチは厳密であり証明を用いて命題を示すが、数値的アプローチは近似的でありアルゴリズムを用いてシミュレーションの事例を示す 解析的アプローチで扱える分布などは限定的だが、数値的アプローチは汎用的でありほぼどのような問題でも解ける 4. 最適化アルゴリズム 要点 最適化問題を解くために、様々なアルゴリズムから効率がよく精度が高いものを選びたい 最適化アルゴリズムでは、初期値や許容誤差などを設定しなければいけない場合があり、これらが適切に設定されなければ、最適解に到達しないことがある 局所解に収束し、全体解に到達しない場合 最適化問題がとても平らであるため、許容誤差が十分に狭くない場合 変数の次元が増えると探索しなければいけない次元が指数関数的に増える "],["回帰分析と最小二乗法による推定.html", "7 回帰分析と最小二乗法による推定", " 7 回帰分析と最小二乗法による推定 「ベイズの定理」と「最尤法」を用いて、観察から母数についてどう学べるか、という推定の問題を考えてきました。ここでは、2つの確率変数の関係性を分析するための回帰分析とその最も実用的な推定方法である最小二乗法について、2回を通じて学んでいきます。まず、ここでは2つの確率変数の関係について考察し、最小二乗法の概要を説明します。 相関関係と回帰分析の概要* 2つの確率変数の確率分布* 最小二乗法* なぜ「二乗」なのか *講義内容が多いため、1.5回分の講義だと考えてください。 1. 相関関係と回帰分析の概要 要点 多くの事象は、お互いにペアとなって変動する。これらの事象を反映する2つの確率変数\\(X\\)と\\(Y\\)の間に「相関関係がある」と言う 2つの確率変数の観察に相関が見られる理由は、4つある 偶然 \\(X\\)から\\(Y\\)への因果 \\(Y\\)から\\(X\\)への逆因果 交絡因子\\(Z\\)から\\(X\\)と\\(Y\\)への因果 よって、相関は必ずしも因果を示唆しない。しかし、多くの場合、相関は因果を反映している。 \\(X\\)によって\\(Y\\)を説明する関係式を推定することを「回帰分析」と呼ぶ。このとき、\\(X\\)を説明変数もしくは独立変数と呼び、\\(Y\\)を被説明変数もしくは従属変数と呼ぶ 計測した\\(X\\)と\\(Y\\)の関係式に\\(X\\)を代入し、\\(Y\\)の理論値を計算することを「予測」と言う 2. 2つの確率変数の確率分布 要点 あらゆる2つの確率変数\\(X\\)と\\(Y\\)の和について、以下の関係が成り立つ \\[ \\mathbb{E}\\left[X + Y \\right] = \\mu_X + \\mu_Y \\] \\[ V \\left(X + Y \\right) = \\sigma^2_X + \\sigma^2_Y + 2 Cov\\left(X,Y\\right)\\] ここで、 \\(Cov\\left(X,Y\\right)\\ = \\mathbb{E}\\left[\\left(X-\\mu_{X}\\right)\\left(Y-\\mu_{Y}\\right)\\right]\\) を共分散と呼ぶ。 確率変数の値から期待値を差し引き、標準偏差で割ることを、標準化と呼ぶ (すなわち、 \\(X^{\\ast}\\equiv\\frac{X-\\mu_{X}}{\\sigma_{X}}\\), \\(Y^{\\ast}\\equiv\\frac{Y-\\mu_{Y}}{\\sigma_{Y}}\\))。標準化された確率変数の共分散を、相関係数と呼ぶ \\[ \\rho \\equiv \\mathbb{E}\\left[X^\\ast Y^\\ast\\right] \\] また、\\(-1 \\leq \\rho \\leq 1\\) を満たし、相関の強さを表す 2つの確率変数について、独立\\(\\Rightarrow\\)無相関であるが、無相関\\(\\Rightarrow\\)独立ではない 2つの確率変数の分布を同時確率分布と呼び、うち1つの確率変数の特定の値に条件づけた分布を条件つき確率分布と呼ぶ。(それぞれ、密度関数についても同時密度、条件つき密度と呼ぶ。) これらのうち、特に重要なものが二次元正規分布であり、その分散を「分散共分散行列」を用いて表す。(正規分布は分布の形状が特定されているので、二次元正規分布においては、独立と無相関は同値である。) 3. 最小二乗法 要点 単回帰モデル \\[ Y=\\underset{定数項・切片}{\\underbrace{\\beta_{0}}}+\\underset{傾斜・勾配}{\\underbrace{\\beta_{1}}}X+\\underset{誤差項・錯乱項}{\\underbrace{\\varepsilon}} \\] 単回帰モデルの推定 \\[ Y_{i}=\\underset{=\\hat{Y}_{i}...予測値・理論値}{\\underbrace{\\hat{\\beta}_{0}+\\hat{\\beta}_{1}X_{i}}}+\\underset{残差}{\\hat{\\varepsilon_{i}}} \\] 最小二乗法は、残差の二乗の総和\\(\\sum_i \\hat{\\varepsilon_{i}}^2\\) を最小化することによって、推定量\\(\\hat{\\beta}_{0}, \\hat{\\beta}_{1}\\)を得る 勾配\\(\\beta_1\\)が重要なパラメータとなる場合が多く、 \\[ \\beta_{1}=\\frac{Cov\\left(X,Y\\right)}{Var\\left(X\\right)}=\\rho \\frac{\\sigma_Y}{\\sigma_X} \\] である。 データに対する理論モデルの適合度を決定係数\\(R^2\\)で測り、 \\[ R^{2}=\\frac{\\sum_{i}\\left(\\hat{Y}_{i}-\\overline{Y}\\right)^{2}}{\\sum_{i}\\left(Y_{i}-\\overline{Y}\\right)^{2}}=\\frac{理論モデルで説明されるYの変動}{データにおけるYの変動}= \\hat{\\rho}^2 \\] 4. なぜ「二乗」なのか 要点 どの推定方法が適切かは、推定の目的に応じて変わる。しかし、多くの場合、最小二乗法が適切だと考えられる理由がある。 外れ値などがある場合が例外である。 様々な理由から、最小二乗法が望ましい 予測値を「条件つき期待値」として解釈できる 誤差が正規分布をするときの最尤法である 誤差の2次損失関数の期待値を最小化している 補足説明: 2次のテイラー近似は、近似している値(ここでは真の\\(Y_i\\))の近傍のみにおいて適切である。予測値\\(\\hat{Y}_i\\)が大きく乖離するときは、2次の損失関数と、人間の直観的基準が合致しないことがある。 "],["重回帰分析とその条件.html", "8 重回帰分析とその条件", " 8 重回帰分析とその条件 単回帰分析は2つの確率変数の間の関係性を定量化するものでした。しかし、現実にはより多くの事象が影響し、多くの実際のデータセットには複数の説明変数が含まれています。1つの被説明変数と2つ以上の説明変数の関係を明らかにする方法の中で最も実践的なものが重回帰分析であり、実証分析に欠かせない手法です。重回帰分析が望ましい性質を持つ条件を明らかにし、その条件が満たされないときにどのように問題が生じるか、どう対処できるかについて考えていきます。 重回帰分析* 推定量の望ましい性質 重回帰分析の最小二乗法(OLS)によって望ましい推定をするための条件* 外生性条件が満たされないとき* 独立同一分布条件が満たされないとき *講義内容が多いため、1.5回分の講義だと考えてください。 1. 重回帰分析 要点 因果関係 = Ceteris Paribus (他の諸条件を一定にした上で)の関係 複数の説明変数を取る回帰モデルを考え、最小二乗法で推定する \\[ Y=\\beta_{0}+\\beta_{1}X_{1}+\\beta_{2}X_{2}+\\varepsilon \\] \\(X_2\\)が\\(X_1\\)と\\(Y\\)の両方に影響がある場合、それらの影響を取り除くことができ、コントロール変数で制御すると言う 説明変数の数が多くても、残差の推定を用いて、2次元の散布図に視覚化することができる 2. 推定量の望ましい性質 要点 推定量\\(\\hat{\\theta}\\)そのものが確率変数であり、確率分布を持っている。なので、推定量の期待値\\(\\mathbb{E}\\hat{\\theta}\\)や分散 \\(Var\\left(\\hat{\\theta}\\right)\\)を考えられる 有限標本のもとで、不偏性や有効性(最小分散)を満たすことが望ましい 無限標本のもとで、一致性や漸近正規性を満たすことが望ましい 大標本定理により、最尤推定量は多くの場合一致性や漸近正規性を満たす モデルの不確実性に対する頑健性も重要である 補足: 推定量の標準偏差(standard deviation)\\(\\sqrt{Var\\left(\\hat{\\theta}\\right)}\\)を標準誤差(standard error)と呼ぶ 3. 重回帰分析の最小二乗法(OLS)によって望ましい推定をするための条件 要点 ガウス・マルコフの定理: (1)外生性(\\(\\mathbb{E}\\left[\\varepsilon|X\\right]=0\\))と(2)誤差項の独立同一分布(\\(\\mathbb{E}\\left[\\varepsilon^{2}|X\\right]=\\sigma^{2}\\)、\\(\\mathbb{E}\\left[\\varepsilon_{i}\\varepsilon_{j}|X\\right]=0\\))の仮定が満たされるとき、OLSは最小分散不偏線形推定量である。 「線形」とは、パラメータについて線形なモデルという意味で、\\(Y\\)と\\(X\\)の関係が非線形的であるときにも、(i)それぞれを非線形変換するか(ii)\\(X\\)の多項式で重回帰分析をできる 多重共変性に注意しなければならない 4. 外生性条件が満たされないとき 要点 データの不完全性によって外生性が満たされないとき、推定量にバイアスが生じる(\\(\\mathbb{E}\\hat{\\beta}_1 \\neq \\beta_1\\)) コントロール変数が欠落しているとき、欠落変数バイアス(omitted variable bias)が生じる 実際には、全ての説明変数を観察することはできないため、欠落変数バイアスが生じることが多い。「因果推論」の手法は、このバイアスを克服するためにある。 説明変数に測定誤差があるとき、減衰バイアス(attenuation bias)が生じる 説明変数に被説明変数の結果となっている要素があるとき、同時性バイアス(simultaneity bias)が生じる 5. 独立同一分布条件が満たされないとき 要点 誤差項が独立同一分布ではないとき、推定量の期待値(\\(\\mathbb{E}\\hat{\\beta}_1\\))には影響がないが、その分散(\\(Var(\\hat{\\beta}_1)\\))が正しく推定されない どれぐらいその推定量に自信を持ったらよいかを誤ってしまう 不均一分散である(\\(\\mathbb{E}\\left[\\varepsilon^{2}|X\\right] = \\sigma_X^{2}\\))可能性が多いので、『不均一分散に対して頑健な標準誤差』をプログラムで常に使うことが望ましい 系列相関・自己相関がある(\\(\\mathbb{E}\\left[\\varepsilon_{i}\\varepsilon_{j}|X\\right]\\neq0\\))ことが多いので、『クラスター構造に対して頑健な標準誤差』をプログラムで常に使うことが望ましい "],["統計的検定.html", "9 統計的検定", " 9 統計的検定 どれだけ膨大なデータに複雑な分析をしても、他人に伝えられるのは結局、「差があるのかないのか」という結論のみであることもあります。統一的な基準がなければ、最後の結論づけにおいて主観的判断が大きくなり、結論の解釈が難しくなるでしょう。その統一的な基準を「手続き」として定めている概念が統計的検定です。近年、そもそも主観的判断に一切頼らずに判断をしようとすることが概念的混乱を引き起していると指摘されていますが、今までの研究の蓄積を理解するためにこの手続きが鍵となっていることは疑いありません。ここでは、ミクロ経済学における意思決定の枠組みであり、より日々の判断と整合性の高いベイズ学習と期待効用最大化と比べながら、統計的検定の手続きを理解していきます。 統計的検定の概論* 有意性検定と\\(p\\)値* 標本平均と\\(t\\)分布 \\(t\\)検定と信頼区間* 対立仮説と検出力 (ベイズ的)意思決定論と(頻度論的)統計的検定の対比 *講義内容が多いため、1.5回分の講義だと考えてください。 1. 統計的検定の概論 要約 統計的検定…データの情報を、他者に伝えるためにYes-or-Noに集約する「線引き問題」への系統的・伝統的アプローチ コンテクストや目的に応じて適切な基準を選ぶことが理想だが、「主観的」かつ「曖昧」になってしまう 「客観的」かつ「曖昧さのない」統計的検定が導入され、科学研究の共通言語・政策の決定基準となっているが、その恣意性・慣習性・概念的限界に留意して理解したい 2. 有意性検定と\\(p\\)値 要約 主観的意思決定者は、事前確率に基づき、「確からしい事後信念」が十分に強いならばYesと言う(もし強くないならNoと言う) 有意性検定を用いるとき、事前確率を一切想定せず、あらかじめ定められた以下の手続きを経て、統計的に有意ならば「Noとは言わない」と言うか、ある一定の意味でYesと言う(もしくは有意でないならば、「何も言えない」と言う) 『帰無仮説』を設定する 『有意水準』を選択する データに基づき、『\\(p\\)値』(=帰無仮説のもとでデータほど極端な観察をする確率)を計算する \\(p&lt;\\alpha\\)ならば帰無仮説を『棄却』し(=『統計的に有意』である)、\\(p\\geq\\alpha\\)ならば結論を留保する 3. 標本平均と\\(t\\)分布 要約 真の分散は分からないことが多いため、その推定値である不偏標本分散で代入する この不偏標本分散から導出される標準誤差を用いて標準化した値を\\(t\\)値と言い、自由度が\\(N-1\\)の\\(t\\)分布に従う \\(N\\)が小さいとき、\\(t\\)分布の裾は厚い \\(N\\)が大きいとき、\\(t\\)分布は正規分布で近似される 4. \\(t\\)検定と信頼区間 要約 ベイズ的意思決定者は、回帰分析の推定値を、事前信念と組み合わせ、事後信念を形成して意思決定をする 有意性検定では、実際には慣習として、ほとんどの場合、帰無仮説を\\(\\theta_0=0\\)として設定し、有意水準\\(を\\alpha=.05\\)に設定し、片側検定ではなく両側検定で帰無仮説を棄却するかを決める。 幅を持たせた区間推定として、95％信頼区間を考えることが多い。 5. 対立仮説と検出力 要約 統計的に有意でないとき、その理由は推定値$\\(が低いか、標準誤差\\)SE$が大きいかによって、どう結論付けるかは異なることが現実的である 自ら\\(N\\)を選べるとき、目標となる対立仮説\\(\\theta_1 = \\theta^\\ast\\)を設定し、十分に「検出力」のある\\(N\\)を選ぶことによって、帰無仮説を棄却できないときは推定値$$が低いからという理由に限定できる 仮説検定は、有意水準を一定として検出力を最大化するよに検定を設定するので、期待効用最大化と比べて保守的な意思決定基準であると言える 6. (ベイズ的)意思決定論と(頻度論的)統計的検定の対比 要約 \\(p\\)値をどの程度重視すべきか、について今日、学術的な論争がある ベイズ的な意思決定論において、事前分布の役割をゼロにするとき、多くの場合において、頻度論的考えに収束する \\(p\\)値によって『有意な差がある』という意味について明瞭な共通言語が与えられたが、以下の点で限定的である サンプル数が大きくないと、(現実的に)何も言えないこと ランダム化していないと、何も言えないこと 探索的な統計検定をしすぎると、(現実的に)何も言えなくなること 参考図書・文献 東京大学教養学部統計学教室 『基礎統計学I 統計学入門』東京大学出版会、1991年 奥村晴彦 『Wonderful R 1 Rで楽しむ統計』共立出版、2016年 豊田秀樹 『瀕死の統計学を救え！有意性検定から「仮説が正しい確率」へ』朝倉書店、2021年 デイヴィッド・サルツブルグ 『統計学を拓いた異才たち』竹内恵行・熊谷悦生訳、日経ビジネス人文庫、2010年 芝村良 『R.A.フィッシャーの統計理論 推測統計学の形成とその社会的背景』 九州大学出版会、2004年 今井耕介 『社会科学のためのデータ分析入門 上・下』 岩波書店、2018年 栗原伸一・丸山敦史 『統計学図鑑』オーム社、2017年 "],["標本調査について.html", "10 標本調査について", " 10 標本調査について ここまで、確率の概念的基礎づけや統計的推論について考えてきました。ここで、そもそもデータをどう収集するか、という統計分析の第一歩に立ち返りたいと思います。実際の社会経済現象を把握するためには、このデータ収集こそが肝要であり、地道な・地味な作業が求められます。調査から得られる数字を「追う」のではなく、その背後にある統計の標本の定義、標本数、回収率、質問の詳細などを「読んで」こそ、その数字を適切に解釈できると言えるでしょう。 調査統計の色々* 欠測値をどう扱うか* 答えづらい質問への正直な答えをどう引き出すか *今回の講義内容は、「歴史」や「雑談」の要素が多くなっていますが、「なるほど」と聞き流してくれていれば大丈夫です。 1. 調査統計の色々 要点 調査統計には「全数調査」と「標本調査」があり、「全数調査」にかかる費用が大きくなりすぎるとき、その対象母集団の「縮図」となるような「標本調査」を行う 今日の公的統計においては無作為抽出法が標準的であり、単純無作為法のみでなく、「ばらつき」が大きくなるという弱点を補うために多段抽出法や層別抽出法が用いられる 調査にともなう誤差として、標本誤差のみでなく、以下のような非標本誤差がある 単純ミス 無回答 回答の偽り 非標本誤差が時間を通じて一定だと仮定して、「繰り返し横断調査」や「縦断調査」(パネル調査)などを用いて、時系列の変化を使うことが有効である 2. 欠測値をどう扱うか 要点 欠測値のあるデータを削除をしてしまうことがよくあるが、欠測がランダムでない限り、適切な対応ではない 「ないデータをつくることはできない」が、以下のような対応ができる 妥当だと思える回答を代入する 変数の変域が有限の場合、その上限・下限を代入し、「一番大きくて…」「一番小さくて…」というような値の取り得る幅を推定できる 3. 答えづらい質問への正直な答えをどう引き出すか 要点 回答者が他の人から好意的に見られるように答えることを「社会的望ましさバイアス」と言う このバイアスを完全に除去できないが、「ノイズを加える」ことによって、軽減できる 本人ではなく、身近な人について聞く 回答をランダム化する(選択肢のリストのランダム化、回答に乱数を加える、など) 参考図書・文献 佐藤明彦 『数字を追うな 統計を読め データを読み解く力をつける』 日本経済新聞出版社、2013年 東京大学教養学部統計学教室 『基礎統計学II 人文・社会科学の統計学』東京大学出版会、1994年 高井啓二、星野崇宏、野間久史 『欠測データの統計科学 医学と社会科学への応用 調査観察データ解析の実際１』岩波書店、2016年 宮川公男 『統計学の日本史 治国経世への願い』東京大学出版会、2017年 ゲアリー・スミス 『データは騙る 改竄・捏造・不正を見抜く統計学』川添節子訳、早川書房、2019年 "],["統計的因果推論1.html", "11 統計的因果推論(1)", " 11 統計的因果推論(1) ひとは誰しも「よりよい」と信じる方向へ進みたいものですが、現状を認識したら、その現状に対してどのような行動を取ればよいかを考えるでしょう。ここでは、「どのような選択をすればよいか」を考えるプログラム評価のための「統計的因果推論」について考えていきます。この因果推論においても、『未知の確率過程から生ずるデータを用いて、その過程のパラメータを推定する』という基本的考えは同じですが、『比較対象を設定する』という点において、今までの推定と決定的に異なっています。経済学者が長く取り組んできた問題であり、多くの手法・アプローチが考案されてきました。歴史や実例に触れながら、その発想法について2回の講義を通じて考えていきましょう。 潜在的結果と反実仮想にもとづく因果推論 選択効果から処置効果を分別するための識別条件 観測可能な共変量・属性による「マッチング」 時間を通じて安定した属性を制御する固定効果 1. 潜在的結果と反実仮想にもとづく因果推論 要点 因果効果\\(\\tau_i\\)(=諸条件(\\(X\\))を一定とした上で、処置(\\(D\\))を変えたときに生じる結果(\\(Y\\))の差)を考えるためには、比較対象を適切に設定しなくてはいけない 潜在的結果\\(\\{Y^T_i, Y^C_i\\}\\)は、処置の選択\\(\\{T,C\\}\\)によって「事前的に観測しうる」(a pri ori observable)結果である。このとき、\\(i\\)における因果効果とは \\[ \\tau_i =Y^T_i - Y^C_i \\] 事後的には、潜在的結果のうち事実(factual)のみしか観察できず、観測できない結果を反実仮想(counterfactual)と呼ぶ。すなわち、因果効果を推定するとは、すなわち反実仮想を推測することである 2. 選択効果から処置効果を分別するための識別条件 要点 因果効果の推定を、『反実仮想という比較対象の設定問題/ 欠測値の穴埋め問題』と捉えることができる 「主観的」 … 事前信念を用いて、\\(N=1\\)でも学習する 「より客観的」… 個人ではなく集団について、条件付期待値を推定する 処置効果 = 観測される「処置群」と「比較群」の差 - 選択効果 \\[ \\underset{=\\mathbb{E}\\left[\\tau_{i}|T\\right] (処置効果)}{\\underbrace{\\mathbb{E}\\left[Y_{i}^{T}|T\\right]-\\mathbb{E}\\left[Y_{i}^{C}|T\\right]}} = \\underset{=\\text{観察される差}}{\\underbrace{\\mathbb{E}\\left[Y_{i}^{T}|T\\right]-\\mathbb{E}\\left[Y_{i}^{C}|C\\right]}}-\\underset{=\\text{選択効果}}{\\underbrace{(\\mathbb{E}\\left[Y_{i}^{C}|T\\right]-\\mathbb{E}\\left[Y_{i}^{C}|C\\right])}} \\] 補足: 処置を受けた人への効果は、Treatment on Treated (ToT)だけでなく、Average Treatment on Treated (ATT)とも呼ばれる。 「主観的」… 選択効果を他の情報から吟味する(事例研究など) 「より客観的」… 選択効果を除去するような条件(識別条件)を満たすときを見つける 共変量を用いて、観測できる交絡因子を制御する 時系列の処置の変化を用いて、安定している交絡因子を制御する 処置の可能性が無作為になっているような状況を用いて、ほぼ全ての交絡因子を制御する 識別条件が厳しい状況の方がより信頼できるが、より難しい 補足:識別条件の仮定を、データのみから完全に吟味することはできない。 3. 観測できる共変量・属性による「マッチング」 要点 「マッチング」似ているもの同士でペアを組み、比較をすること 重回帰分析で共変量を制御することも、「マッチング」として捉えることができ、制御しきれない交絡因子によって生じる選択効果を欠落変数バイアスとして捉えることができる 重回帰分析における識別条件: \\[ \\mathbb{E}[Y^C|C,X] = \\mathbb{E}[Y^C|T,X] \\] 共変量を含めるかどうかの指針 交絡因子である場合 … Yes 媒介因子である場合 … No 測定誤差を減らせる独立因子である場合 … 基本的にYes 全く関係のない因子である場合 … No どの共変量を含めたらよいか、必ずしも分からないため、様々な共変量を入れて試す「感度分析」が大切である 訂正: 重回帰の3次元の図における\\(\\beta_0\\)は、切片ではなく、\\(D=0\\)の平面かつ回帰平面上の\\(X=0\\)となっている点である。 4. 時間を通じて安定した属性を制御する固定効果 要点 固定効果モデルでは、共変量として、ダミー変数\\(f_i\\)を含める \\[ Y_{it} = \\beta_1 D_{it} + f_i + \\varepsilon_{it} \\] 通常のOLSでは\\(i\\)の間のパターンを捉えるのに対し、固定効果モデルでは\\(i\\)の内のパターンを捉えることとなる 固定効果分析における識別条件: 全ての時点\\(t,s\\)において \\[ \\mathbb{E}[Y_{it}^C|C_{is}] = \\mathbb{E}[Y_{it}^C|T_{is}] \\] 参考図書・文献 William Shadish, Thomas Cook, and Donald Campbell “Experimental and Quasi-Experimental Designs for Generalized Causal Inference.” Houghton Mifflin Company. 2002. Joshua Angrist and Jorn-Steffen Pischke “Mostly Harmless Econometrics: An Empiricist’s Companion”, Princeton University Press, 2009 Guido Imbens and Donald Rubin “Causal Inference for Statistics, Social, and Biomedical Sciences: An Introduction”, Cambridge University Press, 2015 Judea Pearl and Dana MacKenzie “The Book of Why: The New Science of Cause and Effect” Penguine Books, 2019 西山慶彦・新谷元嗣・川口大司・奥井亮『計量経済学 Econometrics: Statistical Data Analysis for Empirical Economics』New Liberal Arts Selection、 有斐閣、2019年 伊藤公一朗 『データ分析の力 因果関係に迫る思考法』光文社新書、2017年 中室牧子、津川友介 『「原因と結果」の経済学 データから真実を見抜く思考法』ダイヤモンド社、2017年 安井翔太・株式会社ホクソエム 『効果検証入門 正しい比較のための因果推論/計量経済学の基礎』 技術評論社、2020年 佐藤俊樹 『社会科学と因果分析 ウェーバーの方法論から知の現在へ』岩波書店、2019年 Esther Duflo, Rachel Glennester, Michael Kremer 『政策評価のための因果関係の見つけ方 ランダム化比較試験入門』小林庸平監訳、日本評論社、2019年 "],["統計的因果推論2.html", "12 統計的因果推論(2)", " 12 統計的因果推論(2) 因果効果の推定のために観測できる変数などで制御する方法を考えました。しかし、このようなアプローチでは「重要な共変量を制御しきれない」という「答え合わせ」の結果をきっかけに、選択効果を除去するような研究デザインにフォーカスをする「実験的アプローチ」が普及していきました。今日、経済学において広く受け入れられている因果関係は、この「実験的アプローチ」に基づくと言ってよいと考えています。ここでは、この「実験的アプローチ」の考え方を紹介し、決して平たんではなかったその成り立ちと、今も論争となっている点についても考えていきます。 1「研究デザイン」にもとづく実験的アプローチ 2 時系列の中の介入を用いる「差の差」推定 3 外生的な第3の変数を用いる「操作変数法」 4 境界の恣意性を用いる方法 5 政策介入を無作為割り付けする「ランダム化比較実験」 6 実験的アプローチの「局所性」と「脱理論性」 講義ビデオを作成していますが、まず要約のメモをアップロードします。 1「研究デザイン」にもとづく実験的アプローチ 1960年代末アメリカで福祉政策のランダム化比較実験が試みられるようになり、従来十分だと考えられてきた「変数を制御する・統計手法で補正するアプローチ」が不十分ではないか、という1980年代末以降の経済学者の経験的共通認識につながった 「実験的アプローチ」 … 「選択効果」が生じない外生的な変動を用いることができる状況 = 研究デザインによって識別条件を満たすような状況に着目 自然実験・疑似実験 フィールド実験 「選択効果」をできる限り小さくしたいということは、すなわち、被験者の(主観的)厚生・自由を犠牲にしている側面がある 2 時系列の中の介入を用いる「差の差」推定 処置群と比較群の間における前後の間の差を考えることで、両群特性の違いを排除する推定方法が「差の差」(difference-in-difference)であり、event studiesとも呼ばれる 識別条件: 並行トレンドの仮定 \\[ \\mathbb{E}\\left[Y_{i1}^{C}-Y_{i0}^{C}|T\\right]=\\mathbb{E}\\left[Y_{i1}^{C}-Y_{i0}^{C}|C\\right] \\] 並行トレンドが満たされないとき 処置の前のトレンドが異なるパターンであるとき 同時に他の政策介入などがあるとき 傾向そのものが逆因果を引き起こすとき 3 外生的な第3の変数を用いる「操作変数法」 操作変数(Instrumental Variable, Z) = 結果Yに直接影響を与えないが、説明変数Xを通じて間接的に影響を与える変数 2段階の最小二乗法: 真のモデルが\\(Y_i = \\beta_0 + \\beta_1 D_i + \\beta_2 X_i + \\varepsilon_i\\)のとき、以下の2段階の回帰分析をし、 \\[ Y_{i}=\\alpha_{0}+\\alpha_{1}Z_{i}+\\nu_{i}\\:(\\text{Reduced form})\\\\ D_{i}=\\gamma_{0}+\\gamma_{1}Z_{i}+\\eta_{i}\\:(\\text{First stage}) \\] その係数を組み合わせて \\[ \\hat{\\beta_1}^{IV} = \\hat{\\alpha_1}/\\hat{\\gamma_1} \\] として捉えることができる 識別条件: (i) 関連性、(ii)除外性、(iii)独立性、(iv)単調性を満たすとき、\\(\\hat{\\beta_1}^{IV}\\)を局所的な平均処置効果(Local Average Treatment Effect)として捉えることができる 外生性を用いることにより、内生性による推定の問題(欠落変数バイアス、減衰バイアス、同時性バイアス)に対処できる 4 境界の恣意性を用いる方法 多くの属性はなだらかに変化することがほとんどであるが、制度が非連続的に変化する近傍において、ほぼ政策のみが変化するような状況がある 識別条件: ランニング変数\\(Z\\)における非連続な点\\(Z^\\ast\\)(カットオフ)の近傍における連続性 … 微小な\\(\\varepsilon &gt;0\\)において、 \\[ \\mathbb{E}\\left[Y_{i}^{C}|C,Z\\in(Z^{\\ast}-\\varepsilon,Z^{\\ast})\\right]=\\mathbb{E}\\left[Y_{i}^{C}|T,Z\\in(Z^{\\ast},Z^{\\ast}+\\varepsilon)\\right] \\] 回帰非連続(regression discontinuity) … 処置効果を知るために、カットオフの右と左を比較 集積分析(bunching analysis) … 選択効果を知るために、カットオフにおける密度を測定 連続的な変化をどの関数形で近似し、その変化を制御するか、論争となることが多い 5 政策介入を無作為割り付けする「ランダム化比較実験」 理想的には、処置群と比較群の平均を比較するのみという極めてシンプルで透明な方法である 識別条件: 「潜在的結果からランダム抽出をできていること」 \\[ \\mathbb{E}\\left[Y_{i}^{C}|C\\right]=\\mathbb{E}\\left[Y_{i}^{C}|T\\right] \\] たとえ「ランダム割付」をしていても、この識別条件を満たさず「内的妥当性」を保障できないことがある 比較群の調整的行動 (プラセボの欠如) 波及効果・研究に参加することの効果 ランダムではない脱落・欠測 「前向き」(prospective)な研究であるからこそ、「後ろ向き」(retrospective)な研究にはないようなステップがある パイロット実験の実施・標本サイズの決定 研究プロトコルの登録・倫理委員会審査の審査 (被験者の厚生を保障するために、時間を遅らせて処置を与えたり、もし悪効果があると分かったら、途中で中止をする) 6 実験的アプローチの「局所性」と「脱理論性」 批判の内容: 実験的アプローチによる選択バイアスの克服は重要だが、まだ解決できていない問題がある(強調する側面の違い) 実験は局所的である 実験は脱理論的である 実験的アプローチを用いる対応 異なる環境における実験を数多く実施して統合する 異なるデザインの実験を組み合わせて、理論を検証できる (理論が正しいことを想定しなくてよい) 構造的アプローチを用いる対応 経済理論モデルを設定 モデル・パラメータを推定・カリブレーション 政策変更シミュレーション "],["感度分析と縮小推定量.html", "13 感度分析と縮小推定量", " 13 感度分析と縮小推定量 "],["交差検証.html", "14 交差検証", " 14 交差検証 "],["統計分析活用の実際と工夫.html", "15 統計分析活用の実際と工夫", " 15 統計分析活用の実際と工夫 "]]
