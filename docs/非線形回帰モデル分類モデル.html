<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>15 非線形回帰モデル・分類モデル | 統計推論再考 – 概念と技法 –</title>
  <meta name="description" content="15 非線形回帰モデル・分類モデル | 統計推論再考 – 概念と技法 –" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="15 非線形回帰モデル・分類モデル | 統計推論再考 – 概念と技法 –" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="15 非線形回帰モデル・分類モデル | 統計推論再考 – 概念と技法 –" />
  
  
  

<meta name="author" content="By Chishio Furukawa" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="分布の推定.html"/>
<link rel="next" href="コミュニケーションの課題.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>




</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>目指すもの</a></li>
<li class="part"><span><b>I はじめに</b></span></li>
<li class="chapter" data-level="1" data-path="主要な8の統計的考え方.html"><a href="主要な8の統計的考え方.html"><i class="fa fa-check"></i><b>1</b> 主要な8の統計的考え方</a></li>
<li class="chapter" data-level="2" data-path="プログラミングの姿勢と技術.html"><a href="プログラミングの姿勢と技術.html"><i class="fa fa-check"></i><b>2</b> プログラミングの姿勢と技術</a></li>
<li class="part"><span><b>II 確率分布</b></span></li>
<li class="chapter" data-level="3" data-path="確率変数と確率分布.html"><a href="確率変数と確率分布.html"><i class="fa fa-check"></i><b>3</b> 確率変数と確率分布</a></li>
<li class="chapter" data-level="4" data-path="典型的分布と大標本定理.html"><a href="典型的分布と大標本定理.html"><i class="fa fa-check"></i><b>4</b> 典型的分布と大標本定理</a></li>
<li class="chapter" data-level="5" data-path="条件づき確率と意思決定.html"><a href="条件づき確率と意思決定.html"><i class="fa fa-check"></i><b>5</b> 条件づき確率と意思決定</a></li>
<li class="part"><span><b>III 最適化</b></span></li>
<li class="chapter" data-level="6" data-path="最尤法と数値的最適化.html"><a href="最尤法と数値的最適化.html"><i class="fa fa-check"></i><b>6</b> 最尤法と数値的最適化</a></li>
<li class="chapter" data-level="7" data-path="回帰分析と最小二乗法.html"><a href="回帰分析と最小二乗法.html"><i class="fa fa-check"></i><b>7</b> 回帰分析と最小二乗法</a></li>
<li class="chapter" data-level="8" data-path="重回帰分析とその条件.html"><a href="重回帰分析とその条件.html"><i class="fa fa-check"></i><b>8</b> 重回帰分析とその条件</a>
<ul>
<li class="chapter" data-level="8.1" data-path="重回帰分析とその条件.html"><a href="重回帰分析とその条件.html#訂正.-講義ビデオでは多重共変性と書いているが正しくは多重共線性である"><i class="fa fa-check"></i><b>8.1</b> <strong>訂正.</strong> 講義ビデオでは「多重共変性」と書いているが、正しくは「多重共線性」である。</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="統計的検定.html"><a href="統計的検定.html"><i class="fa fa-check"></i><b>9</b> 統計的検定</a></li>
<li class="part"><span><b>IV 社会科学の手法</b></span></li>
<li class="chapter" data-level="10" data-path="社会調査.html"><a href="社会調査.html"><i class="fa fa-check"></i><b>10</b> 社会調査</a></li>
<li class="chapter" data-level="11" data-path="因果推論の共変量制御アプローチ.html"><a href="因果推論の共変量制御アプローチ.html"><i class="fa fa-check"></i><b>11</b> 因果推論の共変量制御アプローチ</a></li>
<li class="chapter" data-level="12" data-path="因果推論の実験的アプローチ.html"><a href="因果推論の実験的アプローチ.html"><i class="fa fa-check"></i><b>12</b> 因果推論の実験的アプローチ</a></li>
<li class="part"><span><b>V モデル適合の手法</b></span></li>
<li class="chapter" data-level="13" data-path="モデルの適合度と複雑性.html"><a href="モデルの適合度と複雑性.html"><i class="fa fa-check"></i><b>13</b> モデルの適合度と複雑性</a></li>
<li class="chapter" data-level="14" data-path="分布の推定.html"><a href="分布の推定.html"><i class="fa fa-check"></i><b>14</b> 分布の推定</a></li>
<li class="chapter" data-level="15" data-path="非線形回帰モデル分類モデル.html"><a href="非線形回帰モデル分類モデル.html"><i class="fa fa-check"></i><b>15</b> 非線形回帰モデル・分類モデル</a></li>
<li class="part"><span><b>VI プログラミング実践</b></span></li>
<li class="chapter" data-level="16" data-path="コミュニケーションの課題.html"><a href="コミュニケーションの課題.html"><i class="fa fa-check"></i><b>16</b> コミュニケーションの課題</a></li>
<li class="chapter" data-level="17" data-path="プログラミングの環境管理.html"><a href="プログラミングの環境管理.html"><i class="fa fa-check"></i><b>17</b> プログラミングの環境管理</a></li>
<li class="chapter" data-level="18" data-path="データ分析プログラミング-1.html"><a href="データ分析プログラミング-1.html"><i class="fa fa-check"></i><b>18</b> データ分析プログラミング (1)</a></li>
<li class="chapter" data-level="19" data-path="データ分析プログラミング-2.html"><a href="データ分析プログラミング-2.html"><i class="fa fa-check"></i><b>19</b> データ分析プログラミング (2)</a></li>
<li class="part"><span><b>VII 付録</b></span></li>
<li class="chapter" data-level="20" data-path="授業の形式と内容.html"><a href="授業の形式と内容.html"><i class="fa fa-check"></i><b>20</b> 授業の形式と内容</a></li>
<li class="chapter" data-level="21" data-path="rを学ぶためのリソース.html"><a href="rを学ぶためのリソース.html"><i class="fa fa-check"></i><b>21</b> Rを学ぶためのリソース</a></li>
<li class="chapter" data-level="22" data-path="rパッケージ活用のエラーへの対処.html"><a href="rパッケージ活用のエラーへの対処.html"><i class="fa fa-check"></i><b>22</b> Rパッケージ活用のエラーへの対処</a>
<ul>
<li class="chapter" data-level="" data-path="rパッケージ活用のエラーへの対処.html"><a href="rパッケージ活用のエラーへの対処.html#package-libraryのpathがrstudioに認識されないとき"><i class="fa fa-check"></i>package libraryのpathがRStudioに認識されないとき</a></li>
<li class="chapter" data-level="" data-path="rパッケージ活用のエラーへの対処.html"><a href="rパッケージ活用のエラーへの対処.html#packagesがコンフリクトを起こすとき"><i class="fa fa-check"></i>packagesがコンフリクトを起こすとき</a></li>
<li class="chapter" data-level="" data-path="rパッケージ活用のエラーへの対処.html"><a href="rパッケージ活用のエラーへの対処.html#別の手法-renvパッケージを用いる"><i class="fa fa-check"></i>別の手法: renvパッケージを用いる</a></li>
</ul></li>
<li class="chapter" data-level="23" data-path="補講1-数学.html"><a href="補講1-数学.html"><i class="fa fa-check"></i><b>23</b> 補講(1) 数学</a></li>
<li class="chapter" data-level="24" data-path="補講2-思索への寄り道.html"><a href="補講2-思索への寄り道.html"><i class="fa fa-check"></i><b>24</b> 補講(2) 思索への寄り道</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">統計推論再考 – 概念と技法 –</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="非線形回帰モデル分類モデル" class="section level1" number="15">
<h1><span class="header-section-number">15</span> 非線形回帰モデル・分類モデル</h1>
<p>重回帰分析では、アウトカムが量的変数である線形回帰モデルを主に考えました。ここでは、アウトカムが量的変数で説明変数に対して非線形の関係を持つ回帰モデル、そして質的変数である分類モデルを考えます。これらの統計モデルはとてもたくさんありますが、主要なものを説明します。</p>
<p>また、(少なくとも現時点で)経済学研究に用いられることは多くありませんが、人工ニューラルネットによる機械学習で、従来の統計モデルでは不可能だったデータの分析が可能となっています。これらによって直面しなければならない新しい社会的・哲学的な課題も考えます。</p>
<blockquote>
<ol style="list-style-type: decimal">
<li>潜在変数モデル</li>
<li>多項式と縮小推定量</li>
<li>スプラインと局所回帰による平滑化</li>
<li>決定木、ランダム・フォレストとブースティング</li>
<li>人工ニューラルネットと深層学習</li>
<li>機械学習の「思考」、「創造性」と「倫理的課題」</li>
</ol>
</blockquote>
<hr />
<p><strong>1. 潜在変数モデル</strong></p>
<iframe src="https://player.vimeo.com/video/682623687?h=bafa16d7d7&amp;badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479" width="502" height="360" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen title="Latent Variables.mp4">
</iframe>
<blockquote>
<p>要約</p>
</blockquote>
<ul>
<li><p><span class="math inline">\(Y_i \in \{0,1\}\)</span>に対して、潜在変数<span class="math inline">\(Y_i^\ast = \beta_0 + \sum_{j=1}^k\beta_j X_{ji} + \varepsilon_i\)</span> が閾値<span class="math inline">\(0\)</span>を越える確率として考えることができ、<span class="math inline">\(\varepsilon_i\)</span>の分布を<span class="math inline">\(F\)</span>と書くと、
<span class="math display">\[
\mathbb{E}Y_{i}=F\left(\beta_0 + \sum_{j=1}^k\beta_j X_{ji}\right)
\]</span>
などとして書ける。</p>
<ul>
<li>プロビット(probit) … <span class="math inline">\(F(\varepsilon_i) = \Phi(\varepsilon_i)\)</span>、正規分布を仮定</li>
<li>ロジット(logit) … <span class="math inline">\(F(\varepsilon_i) = \exp(\varepsilon_i)/[1 + \exp(\varepsilon_i)]\)</span> 、ロジスティック分布を仮定</li>
<li>線形確率モデル … <span class="math inline">\(F(\varepsilon_i) = \varepsilon_i + 1/2\)</span> 、一様分布を仮定 (局所的近似として解釈)</li>
</ul></li>
<li><p>限界効果<span class="math inline">\(\partial \mathbb{E}Y_{i}/ \partial X_{li} = \beta_l f\left(\beta_0 + \sum_{j=1}^k\beta_j X_{ji}\right)\)</span>に着目して、係数を解釈する</p></li>
<li><p>被説明変数が離散的で3つ以上の値を取るときにも適用できる</p></li>
</ul>
<hr />
<p><strong>2. 多項式と縮小推定量</strong></p>
<iframe src="https://player.vimeo.com/video/682624971?h=22edcdd0df&amp;badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479" width="502" height="360" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen title="Polynomials and Shrinkage.mp4">
</iframe>
<blockquote>
<p>要約</p>
</blockquote>
<ul>
<li><p>経済学の実証研究で最もよく用いるフレクシブルな非線形モデルは、多項式(polynomial)モデルと交互作用(interaction effects)モデルである</p>
<ul>
<li>多項式モデル … <span class="math inline">\(Y_i = \beta_0 + \beta_1 X_{i} + \beta_2 X_{i}^2 +... + \beta_k X_{i}^k + \varepsilon_i\)</span></li>
<li>交互作用モデル … <span class="math inline">\(Y_i = \beta_0 + \beta_1 X_{1i} + \beta_2 X_{2i} + \beta_3 X_{1i}X_{2i} + \varepsilon_i\)</span></li>
</ul></li>
<li><p>十分な数の項を用いれば、(限定的な変域において)スムーズな関数を任意に近似できる</p></li>
<li><p>変数の間の相関が強いとき(多項式の高次項など)、多重共線性によって推定値の分散がとても大きくなってしまう</p></li>
<li><p>正則化 … 目的関数に罰則項を加え、推定値にバイアスを含めることでバリアンスを減らすことができる
<span class="math display">\[
\sum_i^N \varepsilon_i^2 + \lambda \sum_j^k[\alpha  \beta_j^2 + (1-\alpha) |\beta_j|]
\]</span></p>
<ul>
<li>リッジ回帰 (<span class="math inline">\(\alpha = 1\)</span>) … ベイズ的事前分布としての解釈</li>
<li>LASSO回帰 (<span class="math inline">\(\alpha = 0\)</span>) … 変数の数が標本の数よりも大きいときの変数選択</li>
<li>elastic net回帰 (<span class="math inline">\(\alpha \in (0,1)\)</span>) … リッジ回帰とLASSO回帰の組み合わせ</li>
<li>縮小推定量 … 推定された係数にはバイアスがかかっているため、解釈には注意が必要</li>
<li>交差検証法によって<span class="math inline">\(\lambda, \alpha\)</span>の値を選ぶことができる</li>
</ul></li>
</ul>
<hr />
<p><strong>3. スプラインと局所回帰による平滑化</strong></p>
<iframe src="https://player.vimeo.com/video/682649578?h=a772c1e6cb&amp;badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479" width="502" height="360" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen title="Smoothing.mp4">
</iframe>
<blockquote>
<p>要約</p>
</blockquote>
<ul>
<li><p>テイラー近似 … <span class="math inline">\(x\)</span>の近傍においては、低次元の多項式によってスムーズな関数を近似できる</p></li>
<li><p>スプライン平滑化 (spline, piecewise polynomials) … いくつかの変域に分割し、多項式を変域ごとに推定</p>
<ul>
<li>変域の境界でも<span class="math inline">\(\hat{f}^{\prime \prime}(x)\)</span>が等しくなるという制約のもと、3次の多項式を推定することが多い (cubic spline)</li>
</ul></li>
<li><p>局所回帰 (local regression, LOWESS = locally weighted scatterplot smoothing) … 近傍の観測値により重い比重<span class="math inline">\(w_i(x)\)</span>を置いて、それぞれの値<span class="math inline">\(x\)</span>ごとに回帰をすること
<span class="math display">\[
\min_{\beta} \sum_{i=1}^n w_i(x) (Y_i - \beta_0 - \sum_{l=1}^k\beta_l X_{li})^2
\]</span></p>
<ul>
<li><span class="math inline">\(k = 0\)</span> … カーネル回帰 (kernel regression)</li>
<li><span class="math inline">\(k = 1\)</span> … 局所線形回帰 (local linear regression)</li>
<li>データ全てを記憶する推定方法である</li>
</ul></li>
</ul>
<hr />
<p><strong>4. 決定木、ランダム・フォレストとブースティング</strong></p>
<iframe src="https://player.vimeo.com/video/682626442?h=7bec5725f6&amp;badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479" width="502" height="360" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen title="Trees.mp4">
</iframe>
<blockquote>
<p>要約</p>
</blockquote>
<ul>
<li><p>変数の次元が大きく、高次の交互効果が重要な状況に有効な手法</p></li>
<li><p>決定木 … 説明変数に応じて、不確実性を最小化するような条件分岐を繰り返すことで分類・回帰をするモデル</p></li>
<li><p>決定木の「葉ノード」が十分にあれば、任意の関数に完全に適合できる。しかし、データについて「葉ノード」が多すぎるとき、過剰適合となってしまう</p></li>
<li><p>アンサンブル学習法(ensemble learning) … 複数のモデルを組み合わせて、予測精度を改善する方法</p>
<ol style="list-style-type: decimal">
<li>バギング(<u>b</u>ootstrap <u>agg</u>regat<u>ing</u>)、ランダム・フォレスト … ブートストラップ法で標本サンプルを複製し、それぞれのデータで深い決定木を推定し、統合する推定方法</li>
<li>ブースティング … 浅い決定木を残差に基づいて繰り返し推定し、その結果に比重をつけて統合する方法</li>
</ol></li>
<li><p>適応的なカーネル法と捉えられる</p></li>
</ul>
<hr />
<p><strong>5. 人工ニューラルネットと深層学習</strong></p>
<iframe src="https://player.vimeo.com/video/682665245?h=9da94f912f&amp;badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479" width="502" height="360" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen title="Neural Nets.mp4">
</iframe>
<blockquote>
<p>要約</p>
</blockquote>
<ul>
<li><p>特に画像、音声、テキストなどの「非構造化データ」を分析するためにとても有効な手法</p></li>
<li><p>パーセプトロン … 入力<span class="math inline">\(X\)</span>に重み<span class="math inline">\(w\)</span>をつけ、活性化関数<span class="math inline">\(f()\)</span>を通じて出力<span class="math inline">\(Y\)</span>を決定する関数である
<span class="math display">\[
Y_i = f(w_0 + \sum_k w_k X_{ik})
\]</span></p>
<ul>
<li>例: <span class="math inline">\(f(u) = \max(u, 0)\)</span>、<span class="math inline">\(f(u) = \exp(u)/(1+\exp(u))\)</span></li>
</ul></li>
<li><p>人工ニューラルネットとは、複数のパーセプトロンをつなぎあわせた「隠れ層」を持つ合成関数である</p></li>
<li><p>パーセプトロンが十分に多くあり、活性化関数が非線形であれば、(たとえ「隠れ層」が浅くとも) あらゆる関数を任意に近似できる (万能近似定理)</p></li>
<li><p>深層学習 … 「隠れ層」が多くあるとき、非常に高い予測精度を持つ</p>
<ul>
<li>畳み込みニューラルネット、再帰型ニューラルネットなど</li>
<li>“complexity is a compounded simplicity.”</li>
</ul></li>
<li><p>重要な技術革新を経て、いくつもの「冬の時代」を乗り越えてきた</p>
<ol style="list-style-type: decimal">
<li>逆伝播法</li>
<li>確率的勾配降下、ドロップアウト法などによる最適化</li>
<li>大量のデータ</li>
</ol></li>
<li><p>パラメータの数が膨大なのに汎化能力も高いことから、「二重降下」などの理論的発展につながっている。特徴量空間におけるカーネル法の一種だと捉えられる。</p></li>
<li><p><a href="https://playground.tensorflow.org/">Neural network playground</a>でアルゴリズムを試すことができる</p></li>
</ul>
<hr />
<p><strong>6. 機械学習の「思考」、「創造性」と「倫理的課題」</strong></p>
<iframe src="https://player.vimeo.com/video/682649434?h=74dfc7eca1&amp;badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479" width="502" height="360" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen title="Philosophy.mp4">
</iframe>
<blockquote>
<p>要約</p>
</blockquote>
<ul>
<li><p>「人工知能」を人の知能に対してどのように位置づけるか、が社会的・哲学的問いとなっている</p></li>
<li><p>機械学習 = 明確にプログラム化されずに、自動で学んでいく機械</p>
<ol style="list-style-type: decimal">
<li>特徴量学習・パターン認識</li>
<li>敵対的ゲームによる自動学習</li>
</ol>
<p><span class="math inline">\(\Leftrightarrow\)</span> 従来の考え方 = プログラムされたこと以上のことを機械はできない</p></li>
<li><p>人間の脳を物質と化学反応として理解できるなら、機械は(i)その働きを近似でき、(ii)生物学的制約を克服できる</p></li>
<li><p>機械は「思考」を持ちうるか</p>
<ul>
<li>認知主義的アプローチ = 機械は「意識」を持っているか　</li>
<li>行動主義的アプローチ = チューリング・テスト … 「人とコミュニケーションすることと分別をできなかったら、機械は思考しているとする」</li>
</ul></li>
<li><p>機械は「創造性」を持ちうるか</p>
<ul>
<li><p>創造性 = 既存のアイデアの新しい組み合わせ</p>
<p><span class="math inline">\(\Rightarrow\)</span> 創造 = 潜在的に存在する組み合わせの中で有意義なものを発見するための探索</p>
<ol style="list-style-type: decimal">
<li>広大な探索</li>
<li>適切な評価</li>
</ol></li>
</ul></li>
<li><p>機械に適切な「目的関数」を与えることが難しく、人間がつねに抱えていた倫理的課題をより強く突き付けている。例として…</p>
<ol style="list-style-type: decimal">
<li>コンテンツ推薦システムの中毒性</li>
<li>人種・性別差別をする人材評価システム</li>
<li>炎上発言をするチャットボット</li>
<li>「トロッコ問題」を抱える自動運転システム</li>
<li>覇権国家の監視システム</li>
<li>自律型致死兵器システム (LAWS = Lethal Autonomous Weapons System)</li>
</ol></li>
</ul>
<hr />
<p><strong>参考文献.</strong></p>
<p>西山慶彦・新谷元嗣・川口大司・奥井亮『計量経済学 Econometrics: Statistical Data Analysis for Empirical Economics』New Liberal Arts Selection、 有斐閣、2019年</p>
<p>梅津佑太、西井龍映、上田勇祐 『スパース回帰分析とパターン認識』講談社、2020年</p>
<p>Bradley Efron, Trevor Hastie 『大規模計算時代の統計推論―原理と発展― (Computer Age Statistical Inference: Algorithms, Evidence, and Data Science)』藤澤 洋徳・井手 剛監訳・井尻 善久・井手 剛・牛久 祥孝・梅津 佑太・大塚 琢馬・尾林 慶一・川野 秀一・田栗 正隆・竹内 孝・橋本 敦史・藤澤 洋徳・矢野 恵佑訳 2020. 共立出版</p>
<p>Hal Varian. 2014. “Big Data: New Tricks for Econometrics.” <em>Journal of Economic Perspectives.</em></p>
<p>Susan Athey and Guido Imbens. “Machine Learning Methods That Economists Should Know About” 2019. <em>Annual Review of Economics.</em></p>
<p>岩沢宏和、平松雄司 『入門 Rによる予測モデリング――機械学習を用いたリスク管理のために』2019. 東京図書</p>
<p>今泉允聡『深層学習の原理に迫る　数学の挑戦』岩波書店、2021年</p>
<p>立山秀利 『ディープラーニングAIはどのように学習し、推論しているのか』2021. 日経BP.</p>
<p>Yann LeCun 『ディープラーニング 学習する機械 – ヤン・ルカン、人工知能を語る』2021. 松尾豊監訳/ 小川浩一訳. 講談社</p>
<p>富谷昭夫 『これならわかる機械学習入門』 2021. 講談社</p>
<p>岡野原大輔 『ディープラーニングを支える技術 ——「正解」を導くメカニズム[技術基礎] 』2022. 技術評論社</p>
<p>岡谷貴之 『深層学習　機械学習プロフェッショナルシリーズ』2022. 講談社</p>
<p>川村秀憲、山下倫央、横山想一郎 『人工知能が俳句を詠む　AI一茶くんの挑戦』2021. オーム社</p>
<p>徳井直生 『創るためのAI　機械と創造性のはてしない物語』2021. ビー・エヌ・エヌ</p>
<p>Stuart Russell 『AI新生　人間互換の知能をつくる』(Human Compatible: Artificial Intelligence and the Problem of Control) 松井信彦訳. 2021. みすず書房</p>
<p>Sean Gerrish『スマートマシンはこうして思考する』(How Smart Machines Think) 依田光江訳. 2020. みすず書房</p>
<p>松尾豊 『人工知能は人間を超えるか ディープラーニングの先にあるもの』2015. 角川EPUB選書</p>
<p><a href="https://machinelearningmastery.com/impressive-applications-of-generative-adversarial-networks/" class="uri">https://machinelearningmastery.com/impressive-applications-of-generative-adversarial-networks/</a></p>
<p>Brundage et al. “The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and Mitigation” 2018.</p>

</div>



            </section>

          </div>
        </div>
      </div>
<a href="分布の推定.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="コミュニケーションの課題.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": false
},
"fontsettings": false,
"edit": null,
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
},
"info": false
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
